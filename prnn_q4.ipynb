{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prnn_q4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDam3CdjeGNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fbfa0a-cf08-4b0d-c521-15ba42536fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "path=\"/content/drive/MyDrive/PRNN_A1/\"\n",
        "path_test =path+\"test/\"\n",
        "path_train =path+\"train/\"\n",
        "train_music= path+\"SA1.WAV\"\n",
        "train_phoneme = path+\"SA1.PHN\""
      ],
      "metadata": {
        "id": "Bn_qE6EJNJR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phoneme_dict():\n",
        "    phoneme_list=[\"bcl\",\"dcl\",\"gcl\",\"pcl\",\"tck\",\"kcl\",\"dcl\",\"tcl\",\"b\",\"d\",\"g\",\"p\",\"t\",\"k\",\"dx\",\"q\",\"jh\",\"ch\",\"s\",\"sh\",\"z\",\"zh\",\"f\",\"th\",\"v\",\"dh\",\"m\",\"n\",\"ng\",\"em\",\"en\",\"eng\",\"nx\",\"l\",\"r\",\"w\",\"y\",\"hh\",\"hv\",\"el\",\"iy\",\"ih\",\"eh\",\"ey\",\"ae\",\"aa\",\"aw\",\"ay\",\"ah\",\"ao\",\"oy\",\"ow\",\"uh\",\"uw\",\"ux\",\"er\",\"ax\",\"ix\",\"axr\",\"ax-h\",\"pau\",\"epi\",\"h#\"]\n",
        "    phonemlist_length = 63\n",
        "    #create key value dictionary\n",
        "    dict_timit = {}\n",
        "    for ph in phoneme_list: \n",
        "        if('a' in ph or 'e' in ph or 'i' in ph or 'o' in ph or 'u' in ph):\n",
        "          dict_timit[ph] = 0                                                ##phoneme is vowel\n",
        "        else:\n",
        "          dict_timit[ph] = 1                                                ##phoneme is consonent\n",
        "    return dict_timit\n",
        "\n",
        "phoneme=get_phoneme_dict()\n",
        "print(phoneme)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XKpK3IW52H4",
        "outputId": "d9051ab9-8edb-4acb-a407-00802d13a249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bcl': 1, 'dcl': 1, 'gcl': 1, 'pcl': 1, 'tck': 1, 'kcl': 1, 'tcl': 1, 'b': 1, 'd': 1, 'g': 1, 'p': 1, 't': 1, 'k': 1, 'dx': 1, 'q': 1, 'jh': 1, 'ch': 1, 's': 1, 'sh': 1, 'z': 1, 'zh': 1, 'f': 1, 'th': 1, 'v': 1, 'dh': 1, 'm': 1, 'n': 1, 'ng': 1, 'em': 0, 'en': 0, 'eng': 0, 'nx': 1, 'l': 1, 'r': 1, 'w': 1, 'y': 1, 'hh': 1, 'hv': 1, 'el': 0, 'iy': 0, 'ih': 0, 'eh': 0, 'ey': 0, 'ae': 0, 'aa': 0, 'aw': 0, 'ay': 0, 'ah': 0, 'ao': 0, 'oy': 0, 'ow': 0, 'uh': 0, 'uw': 0, 'ux': 0, 'er': 0, 'ax': 0, 'ix': 0, 'axr': 0, 'ax-h': 0, 'pau': 0, 'epi': 0, 'h#': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_and_y(file_path,phoneme):\n",
        "  x=[]\n",
        "  y=[]\n",
        "  count=0\n",
        "\n",
        "  for folder in os.listdir(file_path):\n",
        "    path = file_path + folder + \"/\"\n",
        "    temp_name=\"\"\n",
        "    for files in os.listdir(path):\n",
        "      name = files.split(\".\")[0]\n",
        "      if name != temp_name:\n",
        "        temp_name=name\n",
        "\n",
        "        wav_file = path + name + \".WAV\"\n",
        "        phn_file = path + name + \".PHN\"\n",
        "        #print(wav_file,phn_file)\n",
        "\n",
        "        data, sampling_freq = librosa.load(wav_file,sr=None, mono=True,offset=0.0,duration=None)\n",
        "        data=data.tolist()\n",
        "\n",
        "        file_obj = open(phn_file, 'r')\n",
        "        phonem_data = file_obj.readlines()\n",
        "        n=np.shape(phonem_data)[0]\n",
        "\n",
        "        for i in range(n):\n",
        "          lower,upper,ph=phonem_data[i].split(\" \")\n",
        "\n",
        "          lower=int(lower)\n",
        "          upper=int(upper)\n",
        "          ph=ph.replace(\"\\n\", \"\")\n",
        "\n",
        "          temp=data[lower:upper]\n",
        "          temp=np.array(temp)\n",
        "\n",
        "          print(count)\n",
        "          count+=1\n",
        "\n",
        "          mfccs = librosa.feature.mfcc(temp, sr=sampling_freq)\n",
        "          # mfccs=mfccs.flatten()\n",
        "          temp=mfccs.tolist()\n",
        "\n",
        "          x.append(temp)\n",
        "          y.append(phoneme[ph])\n",
        "          if(count==1000):\n",
        "            return x,y\n",
        "\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "GrCiMs5ol0Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_feature_len(x):\n",
        "  max_len1=0\n",
        "  max_len2=0\n",
        "  n=x.__len__()\n",
        "  for i in range(n):\n",
        "    max_len1=max(max_len1,np.shape(x[i])[0])\n",
        "    max_len2=max(max_len2,np.shape(x[i])[1])\n",
        "  #print(max_len)\n",
        "  return max_len1,max_len2"
      ],
      "metadata": {
        "id": "ggnoQjq_pyuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(x,max_len):\n",
        "  x_train=[]\n",
        "  n=x.__len__()\n",
        "  # x_train=np.array(x_train)\n",
        "  # for i in range(n):\n",
        "  #   m=np.shape(x[i])[1]\n",
        "  #   temp=np.zeros((20,max_len))\n",
        "  #   if(m>max_len):\n",
        "  #     temp=x[i][:][:max_len]\n",
        "  #   else:\n",
        "  #     temp[0:19][:m]=x[i]\n",
        "    \n",
        "  #   x_train.append(temp)\n",
        "  for i in range(n):\n",
        "    xs=np.zeros((20,max_len))\n",
        "    # m=len(xs)\n",
        "    t=np.shape(x[i])[1]\n",
        "    for j in range(20):\n",
        "      temp=np.array(x[i][j])\n",
        "      if(t<max_len):\n",
        "        xs[j,:t]=temp\n",
        "      else:\n",
        "        xs[j,:]=temp[:max_len]\n",
        "    x_train.append(xs)\n",
        "  return x_train\n",
        " "
      ],
      "metadata": {
        "id": "UvNm2pG2qWy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_audio(path):\n",
        "  \n",
        "  path_test =path+\"test/\"\n",
        "  path_train =path+\"train/\"\n",
        "\n",
        "  phoneme = get_phoneme_dict()\n",
        "  x_train,y_train = get_x_and_y(path_train,phoneme)         \n",
        "\n",
        "  x_test,y_test = get_x_and_y(path_test,phoneme)\n",
        "\n",
        "  max_len = get_max_feature_len(x_train)\n",
        "  max_len=max(max_len,get_max_feature_len(x_test))\n",
        "\n",
        "  # x_train = add_padding(x_train,max_len)\n",
        "  # x_test = add_padding(x_test,max_len)\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "\n",
        "path=\"/content/drive/MyDrive/PRNN_A1/\"\n",
        "x_train, y_train, x_test, y_test = preprocessing_audio(path)\n",
        "#n_test=16533\n",
        "#n_train=57357"
      ],
      "metadata": {
        "id": "sEBOw8euqpP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.shape(x_train[13])[1])\n",
        "# print(np.shape(x_test))\n",
        "max_len1,max_len2 = get_max_feature_len(x_train)\n",
        "t1,t2=get_max_feature_len(x_test)\n",
        "max_len1=max(max_len1,t1)\n",
        "max_len2=max(max_len2,t2)\n",
        "print(max_len1)\n",
        "print(max_len2)\n",
        "max_len=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snmAXpJ_hYBF",
        "outputId": "d5475fda-d16b-49be-d12f-378bc22642b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  print(np.shape(x_train[i]))"
      ],
      "metadata": {
        "id": "tfO8rLd9vHNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.__len__()\n",
        "np.shape(x_train[i])\n",
        "print(i)"
      ],
      "metadata": {
        "id": "HALCctuIujRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = add_padding(x_train,max_len)\n",
        "xtest = add_padding(x_test,max_len)\n",
        "print(xtrain[0:2])\n",
        "# print(xtest)"
      ],
      "metadata": {
        "id": "e7nHhLtVuHEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(xtrain))\n",
        "print(np.shape(xtest))\n",
        "Xtrain = np.array(xtrain[0:1000])\n",
        "Ytrain = np.array(y_train[0:1000])\n",
        "Xtest = np.array(xtest[0:1000])\n",
        "Ytest = np.array(y_test[0:1000])\n"
      ],
      "metadata": {
        "id": "6HCUBCnM6H9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b59400a-028b-4245-f8a8-e242a67ad86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20, 10)\n",
            "(1000, 20, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def one_hot(y):\n",
        "#   one_hot_y = np.zeros((y.size, y.max()+1)).astype(\"float32\")\n",
        "#   one_hot_y[np.arange(y.size), y] = 1\n",
        "#   return one_hot_y\n",
        "# Ytest=one_hot(Ytest)\n",
        "# Ytrain=one_hot(Ytrain)"
      ],
      "metadata": {
        "id": "xjiMNiY-S_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain"
      ],
      "metadata": {
        "id": "akL6AMJETYtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs on the time-series using pyTorch"
      ],
      "metadata": {
        "id": "ixDWs_HICldR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.autograd import Variable "
      ],
      "metadata": {
        "id": "SwpLd5jRRav1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU avail\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "RNc8DCZw0gwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.from_numpy(Xtrain).float()\n",
        "Y_train = torch.from_numpy(Ytrain).float()"
      ],
      "metadata": {
        "id": "6peIMBgjhucY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data,label, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        x = data[i:(i+seq_length)]\n",
        "        y = label[i+seq_length]\n",
        "        x=np.array(x)\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "\n",
        "    return np.array(xs), np.array(ys)"
      ],
      "metadata": {
        "id": "G7nlNR-wTCHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xs,ys=create_sequences(Xtrain,Ytrain,3)\n",
        "X_train = torch.from_numpy(Xtrain).float()\n",
        "Y_train = torch.from_numpy(Ytrain).float()\n",
        "\n",
        "# xs,ys=create_sequences(Xtest,Ytest,3)\n",
        "X_test = torch.from_numpy(Xtest).float()\n",
        "Y_test = torch.from_numpy(Ytest).float()"
      ],
      "metadata": {
        "id": "YKjmsi9bRA1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.size())\n",
        "print(Y_train.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-aFbyzR9q1",
        "outputId": "8f4d395e-9beb-4381-f9ac-05ca075e9cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 20, 10])\n",
            "torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Predictor(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.2):\n",
        "        super(Predictor, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_size = input_size\n",
        "        \n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.linear1 = nn.Linear(hidden_dim, 64)\n",
        "        self.linear2 = nn.Linear(64, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        #x = x.long()\n",
        "        #embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(x, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        \n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        #print(weight)\n",
        "        hidden = ((weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()).to(torch.float32),\n",
        "                      (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()).to(torch.float32))\n",
        "        #print(hidden)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "vqy41dliyIgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(X_train, Y_train)\n",
        "test_data = TensorDataset(X_test, Y_test)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ymW9ADdEq7BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VtFY_4ibhGT",
        "outputId": "89a1c8ab-9e24-4725-8fbf-f1dd144b1180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = 2\n",
        "#embedding_dim = 400\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "input_size = 10\n",
        "\n",
        "model = Predictor(input_size, output_size, hidden_dim, n_layers)\n",
        "#model.to(device)\n",
        "\n",
        "lr=0.00002\n",
        "#criterion = nn.BCELoss()\n",
        "criterion = nn.MSELoss()\n",
        "# criterion=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "JQ0Q-WjQyMf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "counter = 0\n",
        "print_every = 1000\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "losses = []\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "    #h[0] = h[0].to(torch.float32)\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        h = tuple([e.data for e in h])\n",
        "        #inputs = inputs.to(torch.float64)\n",
        "        print(h)\n",
        "        print(len(h))\n",
        "        inputs, labels = inputs, labels.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs, h)\n",
        "\n",
        "        print(output)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        # nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if counter%print_every == 0:\n",
        "            val_h = model.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            num_correct = 0\n",
        "            num_yess = 0 \n",
        "            model.eval()\n",
        "            for inp, lab in test_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                #print(val_h[0].size)\n",
        "                out, val_h = model(inp, val_h)\n",
        "                # lab = lab.squeeze(-1)\n",
        "                val_loss = criterion(out, lab.float())\n",
        "                #val_loss = criterion(out.squeeze(), lab.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "                pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
        "                \n",
        "                correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "                correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "                if (pred == lab):\n",
        "                  yess = 1\n",
        "                  num_yess += 1\n",
        "                else:\n",
        "                  yess = 0\n",
        "                num_correct += np.sum(correct)\n",
        "                \n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "            test_acc = num_correct/len(test_loader.dataset)\n",
        "            print(\"Test accuracy: {:.3f}%\".format(test_acc*100))\n",
        "            if np.mean(val_losses) <= valid_loss_min:\n",
        "                torch.save(model.state_dict(), './state_dict.pt')\n",
        "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
        "                valid_loss_min = np.mean(val_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "ID0vRBFBybUy",
        "outputId": "45ce3bb4-0740-48b3-91ed-a7c472f3f6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]))\n",
            "2\n",
            "tensor([0.4672], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-80cd257bc951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# nn.utils.clip_grad_norm_(model.parameters(), clip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    }
  ]
}