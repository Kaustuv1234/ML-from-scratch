{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676f9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# Importing the StringIO module.\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b30e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1DataLoader():\n",
    "    \n",
    "    def __init__(self,data_path):\n",
    "        self.data = np.load(data_path)\n",
    "    \n",
    "    def train_test_split(self):\n",
    "        \n",
    "        x_train = self.data['train_images'].reshape(self.data['train_images'].shape[0],-1)\n",
    "        x_test = self.data['test_images'].reshape(self.data['test_images'].shape[0],-1)\n",
    "        x_val = self.data['val_images'].reshape(self.data['val_images'].shape[0],-1)\n",
    "        y_train = self.data['train_labels']\n",
    "        y_test = self.data['test_labels']\n",
    "        y_val = self.data['val_labels']\n",
    "        \n",
    "        return x_train,y_train,x_test,y_test,x_val,y_val\n",
    "    \n",
    "    def get_metrics(pred,actual):\n",
    "        n_correct_preds = 0\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for i in range(actual.shape[0]):\n",
    "            if pred[i] == actual[i]:\n",
    "                if actual[i]==1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if actual[i]==1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "\n",
    "        accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "        \n",
    "        if tp+fn==0:\n",
    "            recall= 0 \n",
    "        else:\n",
    "            recall = tp/(tp+fn)\n",
    "        \n",
    "        if tp+fp==0:\n",
    "            precision = 0\n",
    "        else:   \n",
    "            precision = tp/(tp+fp)\n",
    "        \n",
    "        if recall==0 and precision==0:\n",
    "            F1 = 0 \n",
    "        else:\n",
    "            F1 = 2*recall*precision/(recall+precision)\n",
    "\n",
    "        if tn+fp==0:\n",
    "            specificity = 0\n",
    "        else:\n",
    "            specificity = tn/(tn+fp)\n",
    "        \n",
    "        AUC = (recall + specificity)/2\n",
    "\n",
    "        return accuracy,F1,AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2DataLoader():\n",
    "    \n",
    "    def __init__(self,data_path):\n",
    "        self.data = np.load(data_path)\n",
    "    \n",
    "    def train_test_split(self):\n",
    "        \n",
    "        x_train = self.data['train_images'].reshape(self.data['train_images'].shape[0],-1)\n",
    "        x_test = self.data['test_images'].reshape(self.data['test_images'].shape[0],-1)\n",
    "        x_val = self.data['val_images'].reshape(self.data['val_images'].shape[0],-1)\n",
    "        y_train = self.data['train_labels']\n",
    "        y_test = self.data['test_labels']\n",
    "        y_val = self.data['val_labels']\n",
    "    \n",
    "        return x_train,y_train,x_test,y_test,x_val,y_val\n",
    "    \n",
    "    def confusion_mat(self,actual, pred):\n",
    "        \n",
    "        classes = 8\n",
    "        mat = np.zeros((8, 8))\n",
    "        for i, j in zip(actual, pred):\n",
    "            mat[i][j] += 1\n",
    "        return mat\n",
    "\n",
    "    def get_metrics(self, y_prediction,y_true):\n",
    "        \n",
    "        y_true = y_true.reshape((-1,)).astype(np.int64)\n",
    "        y_prediction = y_prediction.astype(np.int64)\n",
    "        cnf_matrix = confusion_mat(y_true, y_prediction)\n",
    "        # print(cnf_matrix)\n",
    "        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "        TP = np.diag(cnf_matrix)\n",
    "        TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "        FP = FP.astype(float)\n",
    "        FN = FN.astype(float)\n",
    "        TP = TP.astype(float)\n",
    "        TN = TN.astype(float)\n",
    "        div = TP+FN\n",
    "        TPR = [0 if d==0 else 1/d for d in div]\n",
    "        TPR = TPR * TP\n",
    "\n",
    "        div = TN+FP\n",
    "        TNR = [0 if d==0 else 1/d for d in div]\n",
    "        TNR = TNR * TN\n",
    "\n",
    "        div = TP+FP\n",
    "        PPV = [0 if d==0 else 1/d for d in div]\n",
    "        PPV = PPV * TP\n",
    "\n",
    "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "        AUC = (TNR + TPR)/2\n",
    "        div = TPR + PPV\n",
    "        F1 = [0 if d==0 else 1/d for d in div]\n",
    "        F1 *= 2*TPR*PPV\n",
    "\n",
    "        return ACC, F1, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd25ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q3DataLoader():\n",
    "    \n",
    "    def __init__(self,ann_path,im_path):\n",
    "        \n",
    "        self.ann_path = ann_path\n",
    "        self.im_path = im_path\n",
    "    \n",
    "    def get_file_list(self,root, file_type):\n",
    "        return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]\n",
    "\n",
    "    def get_train_df(self,ann_path, img_path):\n",
    "    \n",
    "        ann_path_list = self.get_file_list(self.ann_path, '.xml')\n",
    "        ann = np.zeros((len(ann_path_list),4))\n",
    "        for i in range(len(ann_path_list)):\n",
    "            a_path = ann_path_list[i]\n",
    "            root = ET.parse(a_path).getroot()\n",
    "            ann[i][0] = int(root.find(\"./object/bndbox/xmin\").text)\n",
    "            ann[i][1] = int(root.find(\"./object/bndbox/ymin\").text)\n",
    "            ann[i][2] = int(root.find(\"./object/bndbox/xmax\").text)\n",
    "            ann[i][3] = int(root.find(\"./object/bndbox/ymax\").text)\n",
    "        return ann\n",
    "\n",
    "    def get_image_data(self):\n",
    "    \n",
    "        image_list = get_file_list(self.im_path,'png')\n",
    "        image_data = [ cv2.imread(image_path) for image_path in image_list]\n",
    "\n",
    "        return image_data\n",
    "    \n",
    "    def resize_image_bounding_box(self):\n",
    "        \n",
    "        image_data = self.get_image_data()\n",
    "        targetSize = (100,100)\n",
    "        image_list = get_file_list(self.im_path,'png')\n",
    "        resized_image_list = []\n",
    "        for i in range(len(image_data)):\n",
    "            x_scale = 100/image_data[i].shape[0]\n",
    "            y_scale = 100/image_data[i].shape[1]\n",
    "            train_box[i][0] = int(np.round(train_box[i][0]*x_scale))\n",
    "            train_box[i][1] = int(np.round(train_box[i][1]*y_scale))\n",
    "            train_box[i][2] = int(np.round(train_box[i][2]*x_scale))\n",
    "            train_box[i][3] = int(np.round(train_box[i][3]*y_scale))\n",
    "            image = cv2.imread(image_list[i])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) ## grayscale image\n",
    "            norm_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F) ## normalize\n",
    "            image = cv2.resize(norm_image,targetSize)  ## resize to 100*100\n",
    "            #print(image.shape)\n",
    "            image = np.array(image)\n",
    "            resized_image_list.append(image.ravel())\n",
    "\n",
    "        return train_box,np.array(resized_image_list)  \n",
    "    \n",
    "    def train_test_split(self):\n",
    "        \n",
    "        train_box,resized_image_list = self.resize_image_bounding_box()\n",
    "        return train_test_split(resized_image_list, train_box, test_size=0.3, random_state=34)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q4_DataLoader():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.phoneme = {}\n",
    "        phoneme_list = [\"bcl\",\"dcl\",\"gcl\",\"pcl\",\"tck\",\"kcl\",\"dcl\",\"tcl\",\"b\",\"d\",\"g\",\"p\",\"t\",\"k\",\"dx\",\"q\",\"jh\",\"ch\",\"s\",\"sh\",\"z\",\"zh\",\"f\",\"th\",\"v\",\"dh\",\"m\",\"n\",\"ng\",\"em\",\"en\",\"eng\",\"nx\",\"l\",\"r\",\"w\",\"y\",\"hh\",\"hv\",\"el\",\"iy\",\"ih\",\"eh\",\"ey\",\"ae\",\"aa\",\"aw\",\"ay\",\"ah\",\"ao\",\"oy\",\"ow\",\"uh\",\"uw\",\"ux\",\"er\",\"ax\",\"ix\",\"axr\",\"ax-h\",\"pau\",\"epi\",\"h#\"]\n",
    "        phonemlist_length = 63\n",
    "        #create key value dictionary\n",
    "        for ph in phoneme_list: \n",
    "            if('a' in ph or 'e' in ph or 'i' in ph or 'o' in ph or 'u' in ph):\n",
    "                self.phoneme[ph] = 0                                                ##phoneme is vowel\n",
    "            else:\n",
    "                self.phoneme[ph] = 1\n",
    "    \n",
    "    def get_max_feature_len(self,x):\n",
    "        \n",
    "        max_len = 0\n",
    "        n=x.__len__()\n",
    "        for i in range(n):\n",
    "            max_len = max(max_len,x[i].__len__())\n",
    "        return max_len\n",
    "    \n",
    "    def add_padding(self,x,max_len):\n",
    "    \n",
    "        x_train = []\n",
    "        n = x.__len__()\n",
    "        for i in range(n):\n",
    "            m=x[i].__len__()\n",
    "            temp=np.zeros(max_len)\n",
    "            if(m>max_len):\n",
    "                temp=x[i][:max_len]\n",
    "            else:\n",
    "                temp[:m]=x[i]\n",
    "\n",
    "            x_train.append(temp)\n",
    "        return x_train\n",
    "\n",
    "    def get_x_and_y(self,file_path):\n",
    "    \n",
    "        x = []\n",
    "        y = []\n",
    "        count = 0\n",
    "        for folder in os.listdir(file_path):\n",
    "            \n",
    "            path = file_path + folder + \"/\"\n",
    "            temp_name = \"\"\n",
    "            for files in os.listdir(path):\n",
    "                name = files.split(\".\")[0]\n",
    "                if name != temp_name:\n",
    "                    temp_name = name\n",
    "                wav_file = path + name + \".WAV\"\n",
    "                phn_file = path + name + \".PHN\"\n",
    "\n",
    "                data, sampling_freq = librosa.load(wav_file,sr=None, mono=True,offset=0.0,duration=None)\n",
    "                data=data.tolist()\n",
    "\n",
    "                file_obj = open(phn_file, 'r')\n",
    "                phonem_data = file_obj.readlines()\n",
    "                n=np.shape(phonem_data)[0]\n",
    "\n",
    "                for i in range(n):\n",
    "                    \n",
    "                    lower,upper,ph=phonem_data[i].split(\" \")\n",
    "                    lower = int(lower)\n",
    "                    upper = int(upper)\n",
    "                    ph = ph.replace(\"\\n\", \"\")\n",
    "                    temp = data[lower:upper]\n",
    "                    temp = np.array(temp)\n",
    "                    count += 1\n",
    "                    mfccs = librosa.feature.mfcc(temp, sr=sampling_freq)\n",
    "                    mfccs = mfccs.flatten()\n",
    "                    temp = mfccs.tolist()\n",
    "                    x.append(temp)\n",
    "                    y.append(self.phoneme[ph])\n",
    "                    \n",
    "        return x,y\n",
    "    \n",
    "    def preprocessing_audio(self,path):\n",
    "  \n",
    "        path_test  = path + \"test/DR1/\"\n",
    "        path_train = path + \"train/DR1/\"\n",
    "        x_train,y_train = self.get_x_and_y(path_train)         \n",
    "        x_test,y_test = self.get_x_and_y(path_test)\n",
    "        max_len = self.get_max_feature_len(x_train)\n",
    "        max_len = max(max_len,self.get_max_feature_len(x_test))\n",
    "        x_train = self.add_padding(x_train,max_len)\n",
    "        x_test = self.add_padding(x_test,max_len)\n",
    "\n",
    "        return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "    \n",
    "    def get_metrics(self,pred,actual):\n",
    "        n_correct_preds = 0\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        fn = 0\n",
    "        for i in range(actual.shape[0]):\n",
    "            if pred[i] == actual[i]:\n",
    "                if actual[i]==1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if actual[i]==1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        \n",
    "        return tp/actual.shape[0],fp/actual.shape[0],tn/actual.shape[0],fn/actual.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf663be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiments():\n",
    "    \n",
    "    def __init__():\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def binary_experiments(X,y,x_test,y_test,counts):\n",
    "        \n",
    "        clf = LogisticRegression('Elastic',0.001,0.1)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Elastic Net Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "        clf = LogisticRegression(None,None,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of L1 Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "        clf = LogisticRegression('L1',0.001,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of L1 Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "        clf = LogisticRegression('L2',0.001,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of L2 Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "\n",
    "        clf = LDA(n_classes=2,n_features = x_train.shape[1])\n",
    "        clf.fit(X,counts)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of LDA = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = Multiclass_Gaussian_Naive_Bayes(x_train.shape[1],2)\n",
    "        clf.fit(X,counts)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Multiclass Gaussian Naive Bayes = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = KNearestNeighbor(X,y,10)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of K nearest neighbor = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = GMM_classification(n_classes=2,n_clusters=3)\n",
    "        pred = clf.fit_predict(X,x_test,counts)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'accuracy of GMM with 3 clusters per class = {accuracy,F1,AUC}')\n",
    "\n",
    "        clf = GaussianMLE(n_classes=2)\n",
    "        clf.fit(X,counts)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of my Gaussian MLE = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = ParzenWindow(X,n_classes = 2)\n",
    "        pred = clf.predict(x_test,counts)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Parzen Window = {accuracy,F1,AUC}') \n",
    "        \n",
    "    def multi_class_experiments(X,y,x_test,y_test,counts):\n",
    "        \n",
    "        clf = Multiclass_Logistic_Regression(None,None,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of  Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "        \n",
    "        clf = Multiclass_Logistic_Regression('Elastic',0.1,0.5)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Elastic Net Logistic Regression  = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "        clf = Multiclass_Logistic_Regression('L1',0.1,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of L1 Logistic Regression  = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "\n",
    "        clf = Multiclass_Logistic_Regression('L2',0.1,None)\n",
    "        clf.fit(X,y)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of L2 Logistic Regression = {accuracy,F1,AUC}')\n",
    "        clf.plots()\n",
    "        \n",
    "        clf = Multiclass_Gaussian_Naive_Bayes(x_train.shape[1],8)\n",
    "        clf.fit(X,counts)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Multiclass Gaussian Naive Bayes = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = Multi_LDA(n_classes=8,n_features = x_train.shape[1])\n",
    "        clf.fit(X,counts)\n",
    "        pred = clf.predict(x_test,n_components = 7)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Multiclass LDA = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = ParzenWindow(X_transformed,n_classes = 8)\n",
    "        pred = clf.predict(x_test_transformed,counts)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Parzen Window = {accuracy,F1,AUC}')\n",
    "\n",
    "        clf = GMM_classification(n_classes=8,n_clusters=3)\n",
    "        pred = clf.fit_predict(X_transformed,x_test_transformed,counts)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of GMM classification = {accuracy,F1,AUC}')\n",
    "\n",
    "        clf = KNearestNeighbor(X,y,1)\n",
    "        pred = clf.predict(x_test)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of K nearest neighbor = {accuracy,F1,AUC}') \n",
    "\n",
    "        clf = GaussianMLE(n_classes=8)\n",
    "        clf.fit(X_transformed,counts)\n",
    "        pred = clf.predict(x_test_transformed)\n",
    "        accuracy,F1,AUC = get_metrics(pred,y_test)\n",
    "        print(f'metrics of Gaussian MLE = {accuracy,F1,AUC}') \n",
    "    \n",
    "    \n",
    "    def Regression_experiments():\n",
    "        \n",
    "        clf = LinearRegression(1e-7,None,None,None)\n",
    "        clf.fit(X_train,y_train)\n",
    "        training_errors = np.array(clf.training_errors)\n",
    "        training_MAE = np.array(clf.MAE)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "        print(f'metrics for Simple Linear are {MSE,mIoU,MAE}')\n",
    "        clf.plot_loss()\n",
    "\n",
    "        clf = LinearRegression(1e-7,0.1,'L1',None)\n",
    "        clf.fit(X_train,y_train)\n",
    "        training_errors = np.array(clf.training_errors)\n",
    "        training_MAE = np.array(clf.MAE)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "        print(f'metrics for L1 are {MSE,mIoU,MAE}')\n",
    "        clf.plot_loss()\n",
    "\n",
    "        clf = LinearRegression(1e-7,0.1,'L2',None)\n",
    "        clf.fit(X_train,y_train)\n",
    "        training_errors = np.array(clf.training_errors)\n",
    "        training_MAE = np.array(clf.MAE)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "        print(f'metrics for L2 are {MSE,mIoU,MAE}')\n",
    "        clf.plot_loss()\n",
    "\n",
    "        clf = LinearRegression(1e-7,0.1,'Elastic',0.1)\n",
    "        clf.fit(X_train,y_train)\n",
    "        training_errors = np.array(clf.training_errors)\n",
    "        training_MAE = np.array(clf.MAE)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "        print(f'metrics for Elastic are {MSE,mIoU,MAE}')\n",
    "        clf.plot_loss()\n",
    "\n",
    "        ## L1 ratio tuning for Elastic Net\n",
    "        L1_ratio = 0.1\n",
    "        while(L1_ratio<1):\n",
    "            clf = LinearRegression(1e-7,0.1,'Elastic',L1_ratio)\n",
    "            clf.fit(X_train,y_train)\n",
    "            training_errors = np.array(clf.training_errors)\n",
    "            training_MAE = np.array(clf.MAE)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "            print(f'metrics for Elastic with L1 ratio = {L1_ratio} are {MSE,mIoU,MAE}')\n",
    "            L1_ratio += 0.2\n",
    "\n",
    "        ## L1 regression Regularization rate tuning\n",
    "        reg_rate = 0.001\n",
    "        while(reg_rate<1):\n",
    "            clf = LinearRegression(1e-7,reg_rate,'L1',None)\n",
    "            clf.fit(X_train,y_train)\n",
    "            training_errors = np.array(clf.training_errors)\n",
    "            training_MAE = np.array(clf.MAE)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "            print(f'metrics for L1 with lambda = {reg_rate} are {MSE,mIoU,MAE}')\n",
    "            reg_rate *= 10\n",
    "\n",
    "\n",
    "        ##  L2 regression Regularization rate tuning\n",
    "\n",
    "        reg_rate = 0.001\n",
    "        while(reg_rate<1):\n",
    "            clf = LinearRegression(1e-7,reg_rate,'L2',None)\n",
    "            clf.fit(X_train,y_train)\n",
    "            training_errors = np.array(clf.training_errors)\n",
    "            training_MAE = np.array(clf.MAE)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "            print(f'metrics for L2 with lambda = {reg_rate} are {MSE,mIoU,MAE}')\n",
    "            reg_rate *= 10\n",
    "\n",
    "        ## Elastic Net hyper parameter tuning\n",
    "\n",
    "        reg_rate = 0.001\n",
    "        while(reg_rate<1):\n",
    "            clf = LinearRegression(1e-7,reg_rate,'Elastic',0.1)\n",
    "            clf.fit(X_train,y_train)\n",
    "            training_errors = np.array(clf.training_errors)\n",
    "            training_MAE = np.array(clf.MAE)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            MSE,mIoU,MAE = clf.getMetrics(y_pred,y_test) \n",
    "            print(f'metrics for Elastic with lambda = {reg_rate} are {MSE,mIoU,MAE}')\n",
    "            reg_rate *= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3b23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiclass_Gaussian_Naive_Bayes():\n",
    "    \n",
    "    def __init__(self,n_features,n_classes):\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.mean = np.zeros((n_classes,n_features))\n",
    "        self.variance = np.zeros((n_classes,n_features))\n",
    "        self.eps = 1e-7\n",
    "        \n",
    "    def fit(self,X,counts):\n",
    "    \n",
    "        for i in range(np.size(counts)):\n",
    "            if i==0:\n",
    "                st_idx = 0\n",
    "            else:\n",
    "                st_idx = np.sum(counts[0:i])\n",
    "            curr_X = X[st_idx:st_idx+counts[i]]\n",
    "            self.mean[i] = np.mean(curr_X,axis = 0)\n",
    "            diff = curr_X - self.mean[i]\n",
    "            self.variance[i] = np.mean(np.square(diff),axis = 0)\n",
    "\n",
    "    def gaussian(self,X, mu, var):\n",
    "        \n",
    "        return 1 / ((2 * np.pi) ** (1 / 2) * var ** 0.5) * np.exp(-0.5 * (X-mu)**2/var)\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        \n",
    "        pred = np.zeros(x_test.shape[0])\n",
    "        \n",
    "        for j in range(x_test.shape[0]):\n",
    "            best_class = 0\n",
    "            best_likelihood = -math.inf\n",
    "            for i in range(self.n_classes):\n",
    "                likelihood = self.gaussian(x_test[j],self.mean[i],self.variance[i])\n",
    "                log_likelihood = np.sum(np.log(likelihood+self.eps))\n",
    "                if best_likelihood < log_likelihood:\n",
    "                    best_likelihood = log_likelihood\n",
    "                    best_class = i\n",
    "            pred[j] = best_class\n",
    "        return pred\n",
    "                \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab1792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    \n",
    "    def __init__(self,n_features,n_classes):\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.S_w = np.zeros((n_features,n_features))\n",
    "        self.S_b = np.zeros((n_features,n_features))\n",
    "        self.mu = np.zeros(n_features)\n",
    "        self.mu_class = np.zeros((self.n_classes,self.n_features))\n",
    "\n",
    "    def fit(self,X,counts):\n",
    "        \n",
    "        self.mu = np.mean(X,axis = 0)\n",
    "        self.mu_class[0] = np.mean(X[0:counts[0],:],axis = 0)\n",
    "        self.mu_class[1] = np.mean(X[counts[0]:,:],axis = 0)\n",
    "        self.S_w = np.dot((X[0:counts[0],:]-self.mu_class[0]).T,X[0:counts[0],:]-self.mu_class[0]) + np.dot((X[counts[0]:,:]-self.mu_class[1]).T,X[counts[0]:,:]-self.mu_class[1])\n",
    "        self.S_b = np.dot((self.mu_class[0] - self.mu_class[1]).T,self.mu_class[0] - self.mu_class[1])\n",
    "            \n",
    "    def predict(self,x_test):\n",
    "        \n",
    "        v = np.dot(np.linalg.pinv(self.S_w),self.mu_class[0] - self.mu_class[1])\n",
    "        pred = [1 if abs(np.dot(x_test[i],v)-np.dot(self.mu_class[0],v))> abs(np.dot(x_test[i],v)-np.dot(self.mu_class[1],v)) else 0 for i in range(x_test.shape[0])]\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LinearRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate,alpha,regularization,L1_ratio):\n",
    "            \n",
    "        self.param = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_rate = alpha\n",
    "        self.regularization = regularization\n",
    "        self.L1_ratio = L1_ratio\n",
    "        self.n_iterations = 2000\n",
    "    def initialize_parameters(self, input_dim,output_dim):\n",
    "        \n",
    "        self.param = np.ones((input_dim,output_dim))\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        l1_ratio = self.L1_ratio\n",
    "        x = np.insert(x, 0, 1, axis=1)\n",
    "        self.training_errors = []\n",
    "        self.MAE = []\n",
    "        self.initialize_parameters(input_dim = x.shape[1],output_dim = y.shape[1])\n",
    "        print(self.param.shape)\n",
    "        # Do gradient descent for n_iterations\n",
    "        for i in tqdm(range(self.n_iterations)):\n",
    "            \n",
    "            self.learning_rate = self.learning_rate/(10**int((i/1000))) ## learning rate decay\n",
    "            y_pred = np.dot(x,self.param)\n",
    "            if self.regularization == None:\n",
    "                mse = np.mean(0.5 * (y - y_pred)**2)\n",
    "                grad_param = np.dot(x.T,(y_pred - y))\n",
    "            elif self.regularization == 'L1':\n",
    "                mse = np.mean(0.5 * (y - y_pred)**2) + self.reg_rate*np.linalg.norm(self.param, ord= 1)\n",
    "                grad_param = np.dot(x.T,(y_pred - y)) + self.reg_rate*np.sign(self.param)\n",
    "            elif self.regularization == 'L2':\n",
    "                mse = np.mean(0.5 * (y - y_pred)**2) + 0.5*self.reg_rate*np.linalg.norm(self.param)**2\n",
    "                grad_param = np.dot(x.T,(y_pred - y)) + self.reg_rate*self.param\n",
    "            elif self.regularization == 'Elastic':\n",
    "                mse = np.mean(0.5 * (y - y_pred)**2) + self.reg_rate*(l1_ratio*np.linalg.norm(self.param, ord= 1)+(1-l1_ratio)*0.5*np.linalg.norm(self.param)**2)\n",
    "                grad_param = np.dot(x.T,(y_pred - y)) + self.reg_rate*((1-l1_ratio)*self.param + l1_ratio*np.sign(self.param))\n",
    "            \n",
    "            self.training_errors.append(mse)\n",
    "            self.MAE.append(np.mean(np.abs(y-y_pred)))\n",
    "            self.param = self.param - self.learning_rate * grad_param\n",
    "        \n",
    "            \n",
    "    def predict(self,x_test):\n",
    "        x_test = np.insert(x_test, 0, 1, axis=1)\n",
    "        pred = np.dot(x_test,self.param)\n",
    "        return pred\n",
    "    \n",
    "    def getMetrics(self,y_pred,actual):\n",
    "        \n",
    "    xA = max(y_pred[0], actual[0])\n",
    "    yA = max(y_pred[1], actual[1])\n",
    "    xB = min(y_pred[2], actual[2])\n",
    "    yB = min(y_pred[3], actual[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (y_pred[2] - y_pred[0] + 1) * (y_pred[3] - y_pred[1] + 1)\n",
    "    boxBArea = (actual[2] - actual[0] + 1) * (actual[3] - actual[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "            \n",
    "    MSE = np.mean(0.5 * (actual - y_pred)**2)\n",
    "    MAE = np.mean(np.abs(actual - y_pred))\n",
    "        \n",
    "        return MSE,MoU/y_pred.shape[0],MAE\n",
    "    \n",
    "    def plot_loss(self):\n",
    "    \n",
    "        iters = np.arange(0,self.n_iterations,1)\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        plt.plot(iters[50:],self.training_errors[50:],label = 'MSE')\n",
    "        plt.plot(iters[50:],self.MAE[50:],label = 'MAE')\n",
    "        plt.xlabel('No. of iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        if self.regularization == None:\n",
    "            plt.title('Simple Linear Regression')\n",
    "            plt.savefig('Q3_LinearRegression.png')\n",
    "        else:\n",
    "            plt.title(f'{self.regularization}Regression')\n",
    "            plt.savefig(f'Q3{self.regularization}.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731d657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self,regularization,reg_rate,l1_ratio,learning_rate=0.001):\n",
    "        self.param = None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = []\n",
    "        self.eps = 1e-7\n",
    "        self.n_iterations = 2000\n",
    "        self.regularization = regularization\n",
    "        self.reg_rate = reg_rate\n",
    "        self.l1_ratio = l1_ratio\n",
    "        \n",
    "    def initialize_parameters(self, X):\n",
    "        n_features = np.shape(X)[1]\n",
    "        self.param = np.ones((n_features,1))\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X,0,1,axis = 1)\n",
    "        y = y.reshape(-1,1)\n",
    "        self.initialize_parameters(X)\n",
    "        l1_ratio = self.l1_ratio\n",
    "        for i in tqdm(range(self.n_iterations)):\n",
    "            \n",
    "            y_pred = self.sigmoid(np.dot(X,self.param))\n",
    "            error = -np.dot(y.T,np.log(y_pred + self.eps)).item()\n",
    "            if self.regularization==None:\n",
    "                self.param -= self.learning_rate * np.dot(X.T,y_pred - y)\n",
    "            elif self.regularization == 'L1':\n",
    "                self.param -= self.learning_rate * (np.dot(X.T,y_pred - y) + self.reg_rate*np.sign(self.param))\n",
    "            elif self.regularization == 'L2':\n",
    "                self.param -= self.learning_rate * (np.dot(X.T,y_pred - y) + self.reg_rate*self.param)\n",
    "            elif self.regularization == 'Elastic':\n",
    "                self.param -= self.learning_rate * (np.dot(X.T,y_pred - y) + self.reg_rate*((1-l1_ratio)*self.param + l1_ratio*np.sign(self.param)))\n",
    "    \n",
    "            self.loss.append(error)                                     \n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.insert(X,0,1,axis = 1)\n",
    "        y_pred = np.round(self.sigmoid(np.dot(X,self.param))).astype(int)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def plots(self):\n",
    "        \n",
    "        iters = np.arange(0,self.n_iterations,1)\n",
    "        fig = plt.figure()\n",
    "        plt.plot(iters,self.loss)\n",
    "        plt.xlabel('No. of iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        if self.regularization == None:\n",
    "            plt.title('Simple Logistic Regression')\n",
    "            plt.savefig('Q1_LogisticRegression.png')\n",
    "        else:\n",
    "            plt.title(f'{self.regularization}_LogisticRegression')\n",
    "            plt.savefig(f'Q1{self.regularization}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff87dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParzenWindow():\n",
    "    def __init__(self,X_train,n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.x_train = X_train\n",
    "        \n",
    "    def predict(self,X_test,counts):\n",
    "        \n",
    "        y_pred = np.zeros((self.n_classes,X_test.shape[0]))\n",
    "        for i in range(np.size(counts)):\n",
    "            if i==0:\n",
    "                st_idx = 0\n",
    "            else:\n",
    "                st_idx = np.sum(counts[0:i])\n",
    "                \n",
    "            curr_X = self.x_train[st_idx:st_idx+counts[i]]\n",
    "            y_pred[i,:] = np.array([np.sum(np.exp(-1*((np.linalg.norm(curr_X - X_test[idx],axis=1))**2))) for idx in range(X_test.shape[0])])\n",
    "        \n",
    "        return np.argmax(y_pred,axis=0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e3a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiclass_Logistic_Regression():\n",
    "    \n",
    "    def __init__(self, regularization,reg_rate,l1_ratio,learning_rate=0.001,n_classes=8):\n",
    "        \n",
    "        self.param = None\n",
    "        self.lr = learning_rate\n",
    "        self.training_errors = []\n",
    "        self.eps = 1e-7\n",
    "        self.n_classes = n_classes\n",
    "        self.regularization = regularization\n",
    "        self.reg_rate = reg_rate\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.n_iterations=1000\n",
    "        \n",
    "    def initialize_parameters(self, X):\n",
    "        \n",
    "        n_features = np.shape(X)[1]\n",
    "        self.param = np.ones((self.n_classes,n_features))\n",
    "    \n",
    "    def one_hot(self,y):\n",
    "\n",
    "        return np.eye(self.n_classes)[y.reshape(-1)]\n",
    "    \n",
    "    def softmax(self,probs):\n",
    "        probs = probs - (np.mean(probs,axis=1)).reshape(-1,1)  \n",
    "        return np.exp(probs)/(np.sum(np.exp(probs),axis = 1) + self.eps).reshape(-1,1)\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X = np.insert(X,0,1,axis=1)\n",
    "        y = self.one_hot(y)\n",
    "        self.initialize_parameters(X)\n",
    "        l1_ratio = self.l1_ratio\n",
    "        for i in tqdm(range(self.n_iterations)):\n",
    "            y_pred = softmax(np.dot(X,self.param.T),axis = 1)\n",
    "            if self.regularization==None:\n",
    "                loss = -1*np.mean(y*np.log(y_pred + self.eps))\n",
    "                grad = np.dot((y_pred-y).T,X)\n",
    "            elif self.regularization == 'L1':\n",
    "                loss = -1*np.mean(y*np.log(y_pred + self.eps)) + self.reg_rate*np.linalg.norm(self.param, ord= 1)\n",
    "                grad =np.dot((y_pred-y).T,X) + self.reg_rate*np.sign(self.param)\n",
    "            elif self.regularization == 'L2':\n",
    "                loss = -1*np.mean(y*np.log(y_pred + self.eps)) + 0.5*self.reg_rate*np.linalg.norm(self.param)**2\n",
    "                grad = np.dot((y_pred-y).T,X) + self.reg_rate*self.param\n",
    "            elif self.regularization == 'Elastic':\n",
    "                loss = -1*np.mean(y*np.log(y_pred + self.eps)) + self.reg_rate*(l1_ratio*np.linalg.norm(self.param, ord= 1)+(1-l1_ratio)*0.5*np.linalg.norm(self.param)**2)\n",
    "                grad = np.dot((y_pred-y).T,X) + self.reg_rate*((1-l1_ratio)*self.param + l1_ratio*np.sign(self.param))\n",
    "            self.training_errors.append(loss)\n",
    "            self.param = self.param - self.lr*grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.insert(X,0,1,axis=1)\n",
    "        y_pred = np.argmax(softmax(np.dot(X,self.param.T),axis=1),axis = 1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def plots(self):\n",
    "        \n",
    "        iters = np.arange(0,self.n_iterations,1)\n",
    "        fig = plt.figure()\n",
    "        plt.plot(iters,self.training_errors)\n",
    "        plt.xlabel('No. of iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        if self.regularization == None:\n",
    "            plt.title('Simple Logistic Regression')\n",
    "            plt.savefig('Q2_LogisticRegression.png')\n",
    "        else:\n",
    "            plt.title(f'{self.regularization}_LogisticRegression')\n",
    "            plt.savefig(f'Q2{self.regularization}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8353a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMLE():\n",
    "    \n",
    "    def __init__(self,n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.eps = 1e-7\n",
    "    \n",
    "    def fit(self,X,counts):\n",
    "        \n",
    "        self.mu = np.zeros((self.n_classes,X.shape[1]))\n",
    "        self.cov = np.zeros((self.n_classes,X.shape[1],X.shape[1]))\n",
    "        \n",
    "        for i in range(len(counts)):\n",
    "            if i==0:\n",
    "                st_idx = 0\n",
    "            else:\n",
    "                st_idx = np.sum(counts[0:i])\n",
    "            curr_X = X[st_idx:st_idx+counts[i]]\n",
    "            self.mu[i] = np.mean(curr_X,axis = 0)\n",
    "            self.cov[i] = np.dot((curr_X-self.mu[i]).T,curr_X-self.mu[i])\n",
    "            \n",
    "    def log_likelihood(self,X, mu, cov):\n",
    "        \n",
    "        sign,log_det = np.linalg.slogdet(cov)\n",
    "        return -0.5*log_det -0.5*np.dot(np.dot((X-mu).T,np.linalg.pinv(cov)),X-mu)\n",
    "\n",
    "    def predict(self,x_test):\n",
    "        \n",
    "        pred = np.zeros(x_test.shape[0])\n",
    "        for i in range(x_test.shape[0]):\n",
    "            best_class = 0\n",
    "            best_likelihood = -math.inf\n",
    "            for j in range(self.n_classes):\n",
    "                log_likelihood = self.log_likelihood(x_test[i],self.mu[j],self.cov[j])\n",
    "                if best_likelihood < log_likelihood:\n",
    "                    best_likelihood = log_likelihood\n",
    "                    best_class = j\n",
    "            pred[i] = best_class\n",
    "        return pred\n",
    "    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558eed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_LDA():\n",
    "\n",
    "    def __init__(self,n_features,n_classes):\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.S_w = np.zeros((n_features,n_features))\n",
    "        self.S_b = np.zeros((n_features,n_features))\n",
    "        self.mu = np.zeros(n_features)\n",
    "        self.mu_class = np.zeros((self.n_classes,self.n_features))\n",
    "\n",
    "    def fit(self,X,counts):\n",
    "        \n",
    "        self.mu = np.mean(X,axis = 0)\n",
    "        for i in range(self.n_classes):\n",
    "            if i==0:\n",
    "                st_idx = 0\n",
    "            else:\n",
    "                st_idx = np.sum(counts[0:i])\n",
    "            curr_X = X[st_idx:st_idx+counts[i]]\n",
    "            self.mu_class[i] = np.mean(curr_X,axis = 0)\n",
    "            self.S_w = self.S_w + np.dot((curr_X - self.mu_class[i]).T,curr_X - self.mu_class[i])\n",
    "            self.S_b = self.S_b + counts[i]*np.dot((self.mu - self.mu_class[i]).T,self.mu - self.mu_class[i])\n",
    "     \n",
    "    def predict(self,x_test,n_components):\n",
    "        \n",
    "        V = np.dot(np.linalg.pinv(self.S_w),self.S_b)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(V)\n",
    "        eigenvectors = eigenvectors.T\n",
    "        eigenList = [(eigenvalues[i],eigenvectors[i,:]) for i in range(len(eigenvalues))]\n",
    "        eigenList = sorted(eigenList,key = lambda x:x[0] ,reverse= True)\n",
    "        for i in range(n_components):\n",
    "            eigenvectors[i,:] = eigenList[i][1]\n",
    "        # Project the data onto eigenvectors\n",
    "        eigenvectors = eigenvectors[0:n_components,:]\n",
    "        projected_X = np.dot(x_test,eigenvectors.T)\n",
    "        print(eigenvectors.shape,projected_X.shape)\n",
    "        projected_mu = np.dot(self.mu_class,eigenvectors.T)\n",
    "        pred = np.zeros(x_test.shape[0])\n",
    "        for i in range(x_test.shape[0]):\n",
    "            best_class = 0\n",
    "            best_dist = math.inf\n",
    "            for j in range(self.n_classes):\n",
    "                if np.linalg.norm(projected_X[i] - projected_mu[j]) < best_dist:\n",
    "                    best_dist = np.linalg.norm(projected_X[i] - projected_mu[j])\n",
    "                    best_class = j\n",
    "            pred[i] = best_class\n",
    "        \n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09069b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbor():\n",
    "    \n",
    "    def __init__(self,x_train,y_train,K):\n",
    "        self.k = K\n",
    "        self.X = x_train\n",
    "        self.y = y_train\n",
    "    \n",
    "    def get_Euclidean_distance(self,x):\n",
    "        \n",
    "        return np.sqrt(np.sum((self.X - x)**2,axis=1))\n",
    "        \n",
    "    def predict(self,x_test):\n",
    "        \n",
    "        pred = np.zeros(x_test.shape[0])\n",
    "        for i in range(x_test.shape[0]):\n",
    "            dist = self.get_Euclidean_distance(x_test[i])\n",
    "            nearest_neighbors = dist.argsort()[0:self.k]\n",
    "            unique,counts = np.unique(self.y[nearest_neighbors], return_counts = True)\n",
    "            pred[i] = unique[np.argmax(counts)]\n",
    "            \n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e213e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "class GMM():\n",
    "\n",
    "    def __init__(self, n_components, n_iters, tol):\n",
    "        self.n_components = n_components\n",
    "        self.n_iters = n_iters\n",
    "        self.tol = tol\n",
    "        self.eps = 1e-7\n",
    "        \n",
    "    def fit(self, X):\n",
    "\n",
    "        # data's dimensionality and responsibility vector\n",
    "        n_row, n_col = X.shape     \n",
    "        self.resp = np.zeros((n_row, self.n_components))\n",
    "        \n",
    "        # initialize parameters\n",
    "        np.random.seed(4)\n",
    "        chosen = np.random.choice(n_row, self.n_components, replace = False)\n",
    "        self.means = X[chosen]\n",
    "        self.weights = np.full(self.n_components, 1 / self.n_components)\n",
    "\n",
    "        shape = self.n_components, n_col, n_col\n",
    "        self.covs = np.full(shape, np.cov(X, rowvar = False))\n",
    "\n",
    "        log_likelihood = 0\n",
    "        self.converged = False\n",
    "        self.log_likelihood_trace = []      \n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            log_likelihood_new = self.Expectation(X)\n",
    "            self.Maximization(X)\n",
    "\n",
    "            if abs(log_likelihood_new - log_likelihood) <= self.tol:\n",
    "                self.converged = True\n",
    "                break\n",
    "  \n",
    "            log_likelihood = log_likelihood_new\n",
    "            self.log_likelihood_trace.append(log_likelihood)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def Expectation(self, X):\n",
    "        \n",
    "        self._compute_log_likelihood(X)\n",
    "        log_likelihood = np.sum(np.log(np.sum(self.resp, axis = 1)+ self.eps) )\n",
    "        self.resp = self.resp / (self.resp.sum(axis = 1, keepdims = 1) + self.eps)\n",
    "        \n",
    "        return log_likelihood\n",
    "\n",
    "    def _compute_log_likelihood(self, X):\n",
    "        self.reg_cov = 1e-6*np.identity(X.shape[1])\n",
    "        assert(np.shape(self.covs[0])==np.shape(self.reg_cov))\n",
    "        for k in range(self.n_components):\n",
    "            prior = self.weights[k]\n",
    "            likelihood = multivariate_normal(self.means[k], self.covs[k]+self.reg_cov).pdf(X)\n",
    "            self.resp[:, k] = prior * likelihood\n",
    "\n",
    "        return self\n",
    "\n",
    "    def Maximization(self, X):\n",
    "\n",
    "        resp_weights = self.resp.sum(axis = 0)\n",
    "        self.weights = resp_weights / X.shape[0]\n",
    "        weighted_sum = np.dot(self.resp.T, X)\n",
    "        self.means = weighted_sum / (resp_weights.reshape(-1, 1) + self.eps)\n",
    "        \n",
    "        for k in range(self.n_components):\n",
    "            diff = (X - self.means[k]).T\n",
    "            weighted_sum = np.dot(self.resp[:, k] * diff, diff.T)\n",
    "            self.covs[k] = weighted_sum / (resp_weights[k]+self.eps)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        self._compute_log_likelihood(X_test)\n",
    "        return np.log(np.sum(self.resp, axis = 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a2b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM_classification():\n",
    "    \n",
    "    def __init__(self,n_classes,n_clusters):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_clusters = n_clusters\n",
    "    \n",
    "    def fit_predict(self,X_train,X_test,counts):\n",
    "        pred = np.zeros((X_test.shape[0],self.n_classes))\n",
    "        for i in range(len(counts)):\n",
    "            if i==0:\n",
    "                st_idx = 0\n",
    "            else:\n",
    "                st_idx = np.sum(counts[0:i])\n",
    "            curr_X = X_train[st_idx:st_idx+counts[i]]\n",
    "            clf = GMM(n_components = 3, n_iters = 50, tol = 1e-4).fit(curr_X)\n",
    "            pred[:,i] = clf.predict(X_test)\n",
    "        return np.argmax(pred,axis = 1)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21a6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b90f06",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2000 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20932\\533166870.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:14<00:00, 138.77it/s]\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of Elastic Net Logistic Regression = (0.8493589743589743, 0.8909512761020882, 0.8042735042735043)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2000 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20932\\533166870.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:13<00:00, 145.09it/s]\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of L1 Logistic Regression = (0.8589743589743589, 0.895734597156398, 0.8222222222222222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2000 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20932\\533166870.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:13<00:00, 144.89it/s]\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of L1 Logistic Regression = (0.8269230769230769, 0.876993166287016, 0.7735042735042735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2000 [00:00<?, ?it/s]C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_20932\\533166870.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:13<00:00, 144.29it/s]\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics of L2 Logistic Regression = (0.8525641025641025, 0.8925233644859814, 0.8102564102564103)\n",
      "metrics of LDA = (0.8365384615384616, 0.8819444444444443, 0.7897435897435897)\n",
      "metrics of Multiclass Gaussian Naive Bayes = (0.8365384615384616, 0.8725, 0.8170940170940171)\n",
      "metrics of K nearest neighbor = (0.8381410256410257, 0.8829663962920046, 0.7918803418803418)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (624,) into shape (1214,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m    111\u001b[0m x_test_transformed \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(x_test)\n\u001b[1;32m--> 113\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m accuracy,F1,AUC \u001b[38;5;241m=\u001b[39m get_metrics(pred,y_test)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy of GMM with 3 clusters per class = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy,F1,AUC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mGMM_classification.fit_predict\u001b[1;34m(self, X_train, X_test, counts)\u001b[0m\n\u001b[0;32m     17\u001b[0m     clf \u001b[38;5;241m=\u001b[39m GMM(n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(curr_X)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#clf = GaussianMixture(n_components=self.n_clusters, random_state=0).fit(X_train)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     pred[:,i] \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(pred,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mGMM.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m,X_test):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresp, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mGMM._compute_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     57\u001b[0m     prior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[k]\n\u001b[0;32m     58\u001b[0m     likelihood \u001b[38;5;241m=\u001b[39m multivariate_normal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans[k], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovs[k]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_cov)\u001b[38;5;241m.\u001b[39mpdf(X)\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresp[:, k] \u001b[38;5;241m=\u001b[39m prior \u001b[38;5;241m*\u001b[39m likelihood\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (624,) into shape (1214,)"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dataset = Q1DataLoader('../Assignment 1/data/pneumoniamnist.npz')\n",
    "    x_train,y_train,x_test,y_test,x_val,y_val = dataset.train_test_split()\n",
    "    #x_train = dataset.normalize_input(x_train)\n",
    "    unique,counts = np.unique(y_train,return_counts= True)\n",
    "    X = np.zeros(x_train.shape)\n",
    "    y = np.zeros(y_train.shape[0],dtype = int)\n",
    "    idx = 0\n",
    "    for label in range(2):\n",
    "        labels = np.where(y_train==label)[0]\n",
    "        for i in range(np.size(labels)):\n",
    "            X[idx] = x_train[labels[i]]\n",
    "            y[idx] = label\n",
    "            idx += 1\n",
    "            \n",
    "    q1_experiments = Experiments()\n",
    "    q1_experiments.binary_experiments(X,y,x_test,y_test,counts)\n",
    "    \n",
    "    dataset = Q2DataLoader('../Assignment 1/data/bloodmnist.npz')\n",
    "    x_train,y_train,x_test,y_test,x_val,y_val = dataset.train_test_split()\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    X = np.zeros(x_train.shape)\n",
    "    y = np.zeros(y_train.shape[0],dtype = int)\n",
    "    idx = 0\n",
    "    for label in range(8):\n",
    "        labels = np.where(y_train==label)[0]\n",
    "        for i in range(np.size(labels)):\n",
    "            X[idx] = x_train[labels[i]]\n",
    "            y[idx] = label\n",
    "            idx += 1\n",
    "    \n",
    "    q2_experiments = Experiments()\n",
    "    q2_experiments.multi_class_experiments(X,y,x_test,y_test,counts)\n",
    "    \n",
    "    \n",
    "    ann_path = '../Assignment 1/data/Road Sign Detection/annotations/'\n",
    "    image_path = '../Assignment 1/data/Road Sign Detection/images/'\n",
    "    dataset = DataLoader(ann_path,image_path)\n",
    "    X_train, X_test, y_train, y_test = dataset.train_test_split()\n",
    "    q3_experiments = Experiments()\n",
    "    q3_experiments.(X_train,y_train,x_test,y_test)\n",
    "    \n",
    "    \n",
    "    path = \"../Assignment 1/data/data/\"\n",
    "    AudioFeatures = AudioFeatureExtractor()\n",
    "    x_train,y_train,x_test,y_test = AudioFeatures.preprocessing_audio(path)\n",
    "    unique,counts = np.unique(y_train,return_counts= True)\n",
    "    X = np.zeros(x_train.shape)\n",
    "    y = np.zeros(y_train.shape[0],dtype = int)\n",
    "    idx = 0\n",
    "    for label in range(2):\n",
    "        labels = np.where(y_train == label)[0]\n",
    "        for i in range(np.size(labels)):\n",
    "            X[idx] = x_train[labels[i]]\n",
    "            y[idx] = label\n",
    "            idx += 1\n",
    "    \n",
    "    q4_experiments = Experiments()\n",
    "    q4_experiments.binary_experiments(X,y,x_test,y_test,counts)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be4c28",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## gaussian Kernel Density estimation from scipy\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class0_kde = gaussian_kde(x0.T,bw_method='scott').evaluate(x_test.T)\n",
    "class1_kde = gaussian_kde(x1.T,bw_method='scott').evaluate(x_test.T)\n",
    "pred_kde_estimate = np.zeros(x_test.shape[0])\n",
    "\n",
    "n_correct_preds = 0\n",
    "for i in range(y_test.shape[0]):\n",
    "    \n",
    "    if class0_kde[i] > class1_kde[i]:\n",
    "        pred_kde_estimate[i] = 0\n",
    "    else:\n",
    "        pred_kde_estimate[i] = 1\n",
    "    if pred_kde_estimate[i] == y_test[i]:\n",
    "        n_correct_preds += 1\n",
    "        \n",
    "accuracy = n_correct_preds/y_test.shape[0]\n",
    "print(accuracy,pred_kde_estimate,y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b83b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "test_pdf0 = [np.mean(multivariate_normal.pdf(x0,x_test[i],np.identity(x0.shape[1]))) for i in range(x_test.shape[0])]\n",
    "test_pdf1 = [np.mean(multivariate_normal.pdf(x1,x_test[i],np.identity(x1.shape[1]))) for i in range(x_test.shape[0])]\n",
    "\n",
    "pred_Parzen = []\n",
    "correct_preds = 0\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    if test_pdf1[i]>test_pdf0[i]:\n",
    "        pred_Parzen.append(1)\n",
    "        if y_test[i] == 1:\n",
    "            correct_preds += 1\n",
    "    else:\n",
    "        pred_Parzen.append(0)\n",
    "        if y_test[i] == 0:\n",
    "            correct_preds += 0\n",
    "print(correct_preds,pred_Parzen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c31078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16745a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e11be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac949467",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d456f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e3c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d9048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b96c29",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfadaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846da1a3",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_name",
   "language": "python",
   "name": "venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
